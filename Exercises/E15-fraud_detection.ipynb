{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset to prevent to modify it by mistake\n",
    "\n",
    "base = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many 0 (*aka negatives*) or 1 (*aka positives*) exist on the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives, positives\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(137924, 797)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"negatives, positives\")\n",
    "\n",
    "(base.Label == 0).sum(), (base.Label == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives, positives [%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9942546550269966, 0.0057453449730033666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"negatives, positives [%]\")\n",
    "\n",
    "(base.Label == 0).sum()/base.Label.count(), (base.Label == 1).sum()/base.Label.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression, a Decision Tree and a Random Forest\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base.drop(['Label'], axis = 1)\n",
    "y = base['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size = 0.7, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* ### Model implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {'LogisticRegression': LogisticRegression(),\n",
    "          'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "          'RandomForestClassifier': RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(index=pd.DataFrame(X_test).index, columns=models.keys())\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>FBeta</th>\n",
       "      <th>Target_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.994089</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>0.455853</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.140152</td>\n",
       "      <td>0.130916</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy        F1     FBeta Target_perc\n",
       "Name                                                            \n",
       "RandomForestClassifier  0.994089  0.115108  0.455853        none\n",
       "DecisionTreeRegressor   0.989091  0.140152  0.130916        none\n",
       "LogisticRegression      0.994113         0         0        none"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "fbeta_score = []\n",
    "name = []\n",
    "target = []\n",
    "\n",
    "for i in np.arange(len(models)):\n",
    "    name.append(pd.DataFrame.from_dict(models).columns[i])\n",
    "    target.append('none')\n",
    "    accuracy.append(metrics.accuracy_score(y_pred.iloc[:,[i]].astype(int), y_test))\n",
    "    f1_score.append(metrics.f1_score(y_pred.iloc[:,[i]].astype(int), y_test))\n",
    "    fbeta_score.append(metrics.fbeta_score(y_pred.iloc[:,[i]].astype(int), y_test, beta=10))\n",
    "\n",
    "results = pd.DataFrame([accuracy, f1_score, fbeta_score, name, target]).T\n",
    "results.rename(columns = {0 : 'Accuracy', 1 : 'F1', 2 : 'FBeta', 3 : 'Name', 4: 'Target_perc'}, inplace = True)\n",
    "results.set_index('Name', inplace=True)\n",
    "results.sort_values(by=['FBeta'], inplace=True, ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LogisticRegression` gives a `0` for `FBeta` because is not calculating no `1` or positives.\n",
    "\n",
    "The `RandomForestClassifier` is best to predict in terms that is the model that gives the best `FBeta` (gives a higher weight for those predictions correct in the positives or `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_________\n",
    "\n",
    "Will be used the function 'UnderSampling' defined in [15-Unbalanced_Datasets](https://github.com/albahnsen/PracticalMachineLearningClass/blob/master/notebooks/15-Unbalanced_Datasets.ipynb)\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Model implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>FBeta</th>\n",
       "      <th>Target_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.990605</td>\n",
       "      <td>0.231827</td>\n",
       "      <td>0.223644</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.981306</td>\n",
       "      <td>0.158009</td>\n",
       "      <td>0.108196</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.969892</td>\n",
       "      <td>0.130465</td>\n",
       "      <td>0.079219</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.952399</td>\n",
       "      <td>0.0917011</td>\n",
       "      <td>0.0521035</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.933465</td>\n",
       "      <td>0.081592</td>\n",
       "      <td>0.0448087</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.952183</td>\n",
       "      <td>0.0778499</td>\n",
       "      <td>0.0442925</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.913569</td>\n",
       "      <td>0.0693402</td>\n",
       "      <td>0.0373615</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.970084</td>\n",
       "      <td>0.0532319</td>\n",
       "      <td>0.0329619</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.880073</td>\n",
       "      <td>0.0552716</td>\n",
       "      <td>0.0292553</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.915035</td>\n",
       "      <td>0.0520107</td>\n",
       "      <td>0.0280922</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy         F1      FBeta Target_perc\n",
       "Model                                                             \n",
       "RandomForestClassifier  0.990605   0.231827   0.223644        0.05\n",
       "RandomForestClassifier  0.981306   0.158009   0.108196         0.1\n",
       "RandomForestClassifier  0.969892   0.130465   0.079219        0.15\n",
       "RandomForestClassifier  0.952399  0.0917011  0.0521035         0.2\n",
       "RandomForestClassifier  0.933465   0.081592  0.0448087        0.25\n",
       "DecisionTreeRegressor   0.952183  0.0778499  0.0442925        0.05\n",
       "RandomForestClassifier  0.913569  0.0693402  0.0373615         0.3\n",
       "LogisticRegression      0.970084  0.0532319  0.0329619         0.2\n",
       "RandomForestClassifier  0.880073  0.0552716  0.0292553        0.35\n",
       "DecisionTreeRegressor   0.915035  0.0520107  0.0280922         0.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_u = pd.DataFrame(index=pd.DataFrame(X_test).index, columns=models.keys())\n",
    "\n",
    "accuracy_u = []\n",
    "f1_score_u = []\n",
    "fbeta_score_u = []\n",
    "name_u = []\n",
    "target_u = []\n",
    "\n",
    "for target_percentage in [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50]:\n",
    "    X_u_train, y_u_train = UnderSampling(X_train.values, y_train, target_percentage, 42)\n",
    "    \n",
    "    for model in models.keys():\n",
    "        models[model].fit(X_u_train, y_u_train)\n",
    "        y_pred_u[model] = models[model].predict(X_test)\n",
    "        \n",
    "    for i in np.arange(len(models)):\n",
    "        name_u.append(str(pd.DataFrame.from_dict(models).columns[i]))\n",
    "        target_u.append(target_percentage)\n",
    "        accuracy_u.append(metrics.accuracy_score(y_pred_u.iloc[:,[i]].astype(int), y_test))\n",
    "        f1_score_u.append(metrics.f1_score(y_pred_u.iloc[:,[i]].astype(int), y_test))\n",
    "        fbeta_score_u.append(metrics.fbeta_score(y_pred_u.iloc[:,[i]].astype(int), y_test, beta=10))\n",
    "\n",
    "results_u = pd.DataFrame([accuracy_u, f1_score_u, fbeta_score_u, name_u, target_u]).T\n",
    "results_u.rename(columns = {0 : 'Accuracy', 1 : 'F1', 2 : 'FBeta', 3 : 'Model', 4: 'Target_perc'}, inplace = True)\n",
    "results_u.set_index('Model', inplace=True)\n",
    "results_u.sort_values(by=['FBeta'], inplace=True, ascending=False)\n",
    "results_u.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the table above, that was sorted to shows these with the best `FScore`, we notice that `RandomForestClassifier` gives the best prediction for any combination of `target_percentage`. \n",
    "\n",
    "`RandomForestClassifier` still running even in unbalanced datasets!\n",
    "\n",
    "What is an interesting found is that, even when the elimination of values (using the `UnderSampling` method), an incrementation of the `target_percentage` does not means a better `FScore`! \n",
    "\n",
    "*Note: Seems a similar process of calibration like the hyperparameters find process*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "Will be used the function 'OverSampling' defined in [15-Unbalanced_Datasets](https://github.com/albahnsen/PracticalMachineLearningClass/blob/master/notebooks/15-Unbalanced_Datasets.ipynb)\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    # in case that exist any Missing Value on the y vector.\n",
    "    aux = pd.DataFrame(y)\n",
    "    aux.fillna(0, inplace=True)\n",
    "    y = aux.values\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>FBeta</th>\n",
       "      <th>Target_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.993753</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.378114</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99368</td>\n",
       "      <td>0.170347</td>\n",
       "      <td>0.366286</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.993632</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.344074</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.993656</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.339496</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99356</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.339057</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99356</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.339057</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99344</td>\n",
       "      <td>0.175227</td>\n",
       "      <td>0.331148</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.993512</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.326017</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.99344</td>\n",
       "      <td>0.138801</td>\n",
       "      <td>0.298455</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.993416</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>0.282715</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy        F1     FBeta Target_perc\n",
       "Model                                                           \n",
       "RandomForestClassifier  0.993753  0.166667  0.378114        0.25\n",
       "RandomForestClassifier   0.99368  0.170347  0.366286         0.3\n",
       "RandomForestClassifier  0.993632  0.153355  0.344074         0.5\n",
       "RandomForestClassifier  0.993656  0.142857  0.339496         0.2\n",
       "RandomForestClassifier   0.99356    0.1625  0.339057         0.1\n",
       "RandomForestClassifier   0.99356    0.1625  0.339057        0.15\n",
       "RandomForestClassifier   0.99344  0.175227  0.331148        0.05\n",
       "RandomForestClassifier  0.993512   0.15625  0.326017         0.4\n",
       "RandomForestClassifier   0.99344  0.138801  0.298455        0.45\n",
       "RandomForestClassifier  0.993416  0.127389  0.282715        0.35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_o = pd.DataFrame(index=pd.DataFrame(X_test).index, columns=models.keys())\n",
    "\n",
    "accuracy_o = []\n",
    "f1_score_o = []\n",
    "fbeta_score_o = []\n",
    "name_o = []\n",
    "target_o = []\n",
    "\n",
    "for target_percentage in [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50]:\n",
    "    X_o_train, y_o_train = OverSampling(X_train.values, y_train, target_percentage, 42)\n",
    "    \n",
    "    for model in models.keys():\n",
    "        models[model].fit(X_o_train, y_o_train)\n",
    "        y_pred_o[model] = models[model].predict(X_test)\n",
    "        \n",
    "    for i in np.arange(len(models)):\n",
    "        name_o.append(str(pd.DataFrame.from_dict(models).columns[i]))\n",
    "        target_o.append(target_percentage)\n",
    "        accuracy_o.append(metrics.accuracy_score(y_pred_o.iloc[:,[i]].astype(int), y_test))\n",
    "        f1_score_o.append(metrics.f1_score(y_pred_o.iloc[:,[i]].astype(int), y_test))\n",
    "        fbeta_score_o.append(metrics.fbeta_score(y_pred_o.iloc[:,[i]].astype(int), y_test, beta=10))\n",
    "\n",
    "results_o = pd.DataFrame([accuracy_o, f1_score_o, fbeta_score_o, name_o, target_o]).T\n",
    "results_o.rename(columns = {0 : 'Accuracy', 1 : 'F1', 2 : 'FBeta', 3 : 'Model', 4: 'Target_perc'}, inplace = True)\n",
    "results_o.set_index('Model', inplace=True)\n",
    "results_o.sort_values(by=['FBeta'], inplace=True, ascending=False)\n",
    "results_o.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result obtained above for the `FBeta` according to different models using the `OverSampling` method (to balance the unbalance dataset), implies that the `RandomForestClassifier` is the best model to predict a positive (or `1`) in the fraud detection context.\n",
    "\n",
    "Additional to it, an important found to highlight is that the best `target_percentage` is not the greater neither the lower of the given.\n",
    "\n",
    "Keep on mind that only were evaluated `target_percentage` in [0 - 0.5] since is considered that, to increase the dataset without a clear limit, to *replicate* positives, will create un unwanted bias that will give us incorrect results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "Will be used the function 'SMOTE' defined in [15-Unbalanced_Datasets](https://github.com/albahnsen/PracticalMachineLearningClass/blob/master/notebooks/15-Unbalanced_Datasets.ipynb)\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    # Calculate the NearestNeighbors\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nearest_neighbour_ = NearestNeighbors(n_neighbors=k + 1)\n",
    "    nearest_neighbour_.fit(X[y==1])\n",
    "    nns = nearest_neighbour_.kneighbors(X[y==1], \n",
    "                                    return_distance=False)[:, 1:]\n",
    "    \n",
    "    \n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "    \n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__=[]\n",
    "    # Select one random neighbor for each example to use as base\n",
    "    for i, sel in enumerate(sel_):\n",
    "        nn__.append(np.random.choice(nns[sel]))\n",
    "    \n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1][sel] - step * (X[y==1][sel] - X[y==1][nn_])\n",
    "    \n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>FBeta</th>\n",
       "      <th>Target_perc</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.993248</td>\n",
       "      <td>0.175953</td>\n",
       "      <td>0.30777</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.992575</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.23962</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.23774</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.990965</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.176977</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.985439</td>\n",
       "      <td>0.12931</td>\n",
       "      <td>0.100232</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.982027</td>\n",
       "      <td>0.0966184</td>\n",
       "      <td>0.0690067</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.984429</td>\n",
       "      <td>0.0898876</td>\n",
       "      <td>0.0688465</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.0864067</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.962035</td>\n",
       "      <td>0.0458937</td>\n",
       "      <td>0.0271534</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.98527</td>\n",
       "      <td>0.0285261</td>\n",
       "      <td>0.0234007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy         F1      FBeta Target_perc   k\n",
       "Model                                                                 \n",
       "RandomForestClassifier  0.993248   0.175953    0.30777        0.25   5\n",
       "RandomForestClassifier  0.992575   0.162602    0.23962        0.25  15\n",
       "RandomForestClassifier  0.992551   0.162162    0.23774         0.5   5\n",
       "RandomForestClassifier  0.990965   0.160714   0.176977         0.5  15\n",
       "DecisionTreeRegressor   0.985439    0.12931   0.100232        0.25   5\n",
       "DecisionTreeRegressor   0.982027  0.0966184  0.0690067        0.25  15\n",
       "DecisionTreeRegressor   0.984429  0.0898876  0.0688465         0.5   5\n",
       "DecisionTreeRegressor   0.979167  0.0864067   0.058617         0.5  15\n",
       "LogisticRegression      0.962035  0.0458937  0.0271534        0.25   5\n",
       "LogisticRegression       0.98527  0.0285261  0.0234007        0.25  15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_s = pd.DataFrame(index=pd.DataFrame(X_test).index, columns=models.keys())\n",
    "\n",
    "accuracy_s = []\n",
    "f1_score_s = []\n",
    "fbeta_score_s = []\n",
    "name_s = []\n",
    "target_s = []\n",
    "k_s = []\n",
    "\n",
    "for target_percentage in [0.25, 0.5]:\n",
    "    for k in [5, 15]:\n",
    "        X_s_train, y_s_train = SMOTE(X_train.values, y_train, target_percentage, k, seed=3)\n",
    "\n",
    "        for model in models.keys():\n",
    "            models[model].fit(X_s_train, y_s_train)\n",
    "            y_pred_s[model] = models[model].predict(X_test)\n",
    "        \n",
    "        for i in np.arange(len(models)):\n",
    "            name_s.append(str(pd.DataFrame.from_dict(models).columns[i]))\n",
    "            target_s.append(target_percentage)\n",
    "            k_s.append(k)\n",
    "            accuracy_s.append(metrics.accuracy_score(y_pred_s.iloc[:,[i]].astype(int), y_test))\n",
    "            f1_score_s.append(metrics.f1_score(y_pred_s.iloc[:,[i]].astype(int), y_test))\n",
    "            fbeta_score_s.append(metrics.fbeta_score(y_pred_s.iloc[:,[i]].astype(int), y_test, beta=10))\n",
    "\n",
    "results_s = pd.DataFrame([accuracy_s, f1_score_s, fbeta_score_s, name_s, target_s, k_s]).T\n",
    "results_s.rename(columns = {0 : 'Accuracy', 1 : 'F1', 2 : 'FBeta', 3 : 'Model', \n",
    "                            4: 'Target_perc', 5: 'k'}, inplace = True)\n",
    "results_s.set_index('Model', inplace=True)\n",
    "results_s.sort_values(by=['FBeta'], inplace=True, ascending=False)\n",
    "results_s.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the result above, is important to highlight that `target_percentage` is the most important feature for the function `SMOTE`. The results depends, first of `target_percentage` and then `k`.\n",
    "\n",
    "Additional to it, the best result is lower than the found on `OverSampling`.\n",
    "\n",
    "On the other hand `RandomForestClassifier` is not the model that always gives the best prediction; `DecisionTreeRegressor` is giving good results **with the same combinations of `target_percentage` and `k`**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ada = ADASYN(random_state = 42)\n",
    "X_adasyn, y_adasyn = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adasyn = pd.DataFrame(index=pd.DataFrame(X_test).index, columns=models.keys())\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_adasyn, y_adasyn)\n",
    "    y_pred_adasyn[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>FBeta</th>\n",
       "      <th>Target_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.179894</td>\n",
       "      <td>0.253525</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.983396</td>\n",
       "      <td>0.0823373</td>\n",
       "      <td>0.061338</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.572506</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.00976448</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy         F1       FBeta Target_perc\n",
       "Model                                                              \n",
       "RandomForestClassifier  0.992551   0.179894    0.253525        none\n",
       "DecisionTreeRegressor   0.983396  0.0823373    0.061338        none\n",
       "LogisticRegression      0.572506   0.019077  0.00976448        none"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_adasyn = []\n",
    "f1_score_adasyn = []\n",
    "fbeta_score_adasyn = []\n",
    "name_adasyn = []\n",
    "target_adasyn = []\n",
    "\n",
    "\n",
    "for i in np.arange(len(models)):\n",
    "    name_adasyn.append(str(pd.DataFrame.from_dict(models).columns[i]))\n",
    "    target_adasyn.append('none')\n",
    "    accuracy_adasyn.append(metrics.accuracy_score(y_pred_adasyn.iloc[:,[i]].astype(int), y_test))\n",
    "    f1_score_adasyn.append(metrics.f1_score(y_pred_adasyn.iloc[:,[i]].astype(int), y_test))\n",
    "    fbeta_score_adasyn.append(metrics.fbeta_score(y_pred_adasyn.iloc[:,[i]].astype(int), y_test, beta=10))\n",
    "\n",
    "results_adasyn = pd.DataFrame([accuracy_adasyn, f1_score_adasyn, fbeta_score_adasyn, name_adasyn, target_adasyn]).T\n",
    "results_adasyn.rename(columns = {0 : 'Accuracy', 1 : 'F1', 2 : 'FBeta', 3 : 'Model', 4: 'Target_perc'}, inplace = True)\n",
    "results_adasyn.set_index('Model', inplace=True)\n",
    "results_adasyn.sort_values(by=['FBeta'], inplace=True, ascending=False)\n",
    "results_adasyn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>FBeta</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.992431</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.206207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.991181</td>\n",
       "      <td>0.152425</td>\n",
       "      <td>0.175007</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.981162</td>\n",
       "      <td>0.0862471</td>\n",
       "      <td>0.0607198</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.983156</td>\n",
       "      <td>0.0788436</td>\n",
       "      <td>0.0584434</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.570752</td>\n",
       "      <td>0.0196466</td>\n",
       "      <td>0.0100554</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.572506</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.00976448</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy         F1       FBeta   k\n",
       "Model                                                      \n",
       "RandomForestClassifier  0.992431   0.136986    0.206207   5\n",
       "RandomForestClassifier  0.991181   0.152425    0.175007  15\n",
       "DecisionTreeRegressor   0.981162  0.0862471   0.0607198  15\n",
       "DecisionTreeRegressor   0.983156  0.0788436   0.0584434   5\n",
       "LogisticRegression      0.570752  0.0196466   0.0100554  15\n",
       "LogisticRegression      0.572506   0.019077  0.00976448   5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_a = pd.DataFrame(index=pd.DataFrame(X_test).index, columns=models.keys())\n",
    "\n",
    "accuracy_a = []\n",
    "f1_score_a = []\n",
    "fbeta_score_a = []\n",
    "name_a = []\n",
    "k_a = []\n",
    "\n",
    "for k_ in [5, 15]:\n",
    "    ada = ADASYN(n_neighbors = k_,random_state = 42)\n",
    "    X_adasyn, y_adasyn = ada.fit_resample(X_train, y_train)\n",
    "    \n",
    "    for model in models.keys():\n",
    "        models[model].fit(X_adasyn, y_adasyn)\n",
    "        y_pred_a[model] = models[model].predict(X_test)\n",
    "        \n",
    "    for i in np.arange(len(models)):\n",
    "        name_a.append(str(pd.DataFrame.from_dict(models).columns[i]))\n",
    "        k_a.append(k_)\n",
    "        accuracy_a.append(metrics.accuracy_score(y_pred_a.iloc[:,[i]].astype(int), y_test))\n",
    "        f1_score_a.append(metrics.f1_score(y_pred_a.iloc[:,[i]].astype(int), y_test))\n",
    "        fbeta_score_a.append(metrics.fbeta_score(y_pred_a.iloc[:,[i]].astype(int), y_test, beta=10))\n",
    "\n",
    "results_a = pd.DataFrame([accuracy_a, f1_score_a, fbeta_score_a, name_a, k_a]).T\n",
    "results_a.rename(columns = {0 : 'Accuracy', 1 : 'F1', 2 : 'FBeta', 3 : 'Model', 4: 'k'}, inplace = True)\n",
    "results_a.set_index('Model', inplace=True)\n",
    "results_a.sort_values(by=['FBeta'], inplace=True, ascending=False)\n",
    "results_a.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RandomForestClassifier` is the best model so far for predict the `FBeta`, no matter the method used to try to balance the dataset. \n",
    "\n",
    "One of the relevant aspects of `ADASYN` is that implies a best computational performance (even when the processing time was not measured, took less than time that the other methods).\n",
    "\n",
    "On the other hand, the `FBeta` was not improved; in fact, decreased varying the `n_neighbors`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Each result were already commented in each section*\n",
    "\n",
    "As summary, the exercise to balance a unbalance dataset gives better results that only leave it as is obtained; in fact, prevents conceptual issues like the case of `LogisticRegression` without balance it giving always `zeros`/`negatives`/`0`.\n",
    "\n",
    "On the other, depends of each case to take advantage of each method; not the same method gives the same result for every case. Is advised to each the calibration process of the `target_percentage` (similar to the hyperparameters search process).\n",
    "\n",
    "For this case of **fraud detection**, the best method was `OverSampling` with a `FBeta = 0.378114` and `target_percentage = 0.25`, but that does not implies that the `SMOTE` or `ADASYN` methods does not gives better results; in fact, the computational processing of `ADASYN` implies that the can be calibrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
